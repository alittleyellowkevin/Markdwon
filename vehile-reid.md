#   Vehicle Re-Identification

## 2024

- **TANet- Text region attention learning for vehicle re-identification**

> **Engineering Applications of Artificial Intelligence **2024. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2024-TANet- Text region attention learning for vehicle re-identification.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=TANet%3A+Text+region+attention+learning+for+vehicle+re-identification&btnG=) 【引用数：**0】
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/179289c8-02de-4dfb-b4f7-83ffa0e1c47b.png)
>
> **论文引用**：
>
> ```
> @article{hu2024tanet,
>   title={TANet: Text region attention learning for vehicle re-identification},
>   author={Hu, Wenbo and Zhan, Hongjian and Shivakumara, Palaiahnakote and Pal, Umapada and Lu, Yue},
>   journal={Engineering Applications of Artificial Intelligence},
>   volume={133},
>   pages={108448},
>   year={2024},
>   publisher={Elsevier}
> }
> ```
>

- **Day-Night Cross-domain Vehicle Re-identification**

> **CVPR **2024. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2024-Li_Day-Night_Cross-domain_Vehicle_Re-identification_CVPR_2024_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Day-Night+Cross-domain+Vehicle+Re-identification&btnG=) 【引用数：**0】
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/2671de45-735a-4a32-849b-432a97e18e21.png)
>
> **论文引用**：
>
> ```
> @inproceedings{li2024day,
>   title={Day-Night Cross-domain Vehicle Re-identification},
>   author={Li, Hongchao and Chen, Jingong and Zheng, Aihua and Wu, Yong and Luo, Yonglong},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>   pages={12626--12635},
>   year={2024}
> }
> ```

## 

## 2023

- **Strength in Diversity: Multi-Branch Representation Learning for Vehicle Re-Identification** 

> **preprint 2023. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-Multi-Branch Representation Learning For VehicleReId.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Strength+in+Diversity%3A+Multi-Branch+Representation+Learning+for+Vehicle+Re-Identification**+&btnG=) 【引用数：**0**】
>
> **论文引用**：
>
> ```
>@article{almeida2023strength,
>   title={Strength in Diversity: Multi-Branch Representation Learning for Vehicle Re-Identification},
>  author={Almeida, Eurico and Silva, Bruno and Batista, Jorge},
>   journal={arXiv preprint arXiv:2310.01129},
>  year={2023}
> }
> ```
> 
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.50.01.png" alt="截屏2023-11-12 21.50.01 " style="zoom:100%;" />

- **GiT: Graph Interactive Transformer for Vehicle Re-Identification** 

> **IEEE Transactions on Image Processing, 2023. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-GiT_Graph_Interactive_Transformer_for_Vehicle_Re-Identification.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Git%3A+Graph+interactive+transformer+for+vehicle+re-identification&btnG=) 【引用数：0】
>
> **论文引用**：
>
> ```
> @article{shen2023git,
>   title={Git: Graph interactive transformer for vehicle re-identification},
>   author={Shen, Fei and Xie, Yi and Zhu, Jianqing and Zhu, Xiaobin and Zeng, Huanqiang},
>   journal={IEEE Transactions on Image Processing},
>   volume={32},
>   pages={1039--1051},
>   year={2023},
>   publisher={IEEE}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/2352ee29-ba10-4b0e-b4cb-f36781d5d45c.png)

- **FastReID: A Pytorch Toolbox for General Instance Re-identification**

> **Proceedings of the 31st ACM International Conference on Multimedia 2023. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-FastReid.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=FastReID%3A+A+Pytorch+Toolbox+for+General+Instance+Re-identification&btnG=) 【引用数：**218**】
>
> **论文引用**：
>
> ```
>@inproceedings{he2023fastreid,
>   title={Fastreid: A pytorch toolbox for general instance re-identification},
>  author={He, Lingxiao and Liao, Xingyu and Liu, Wu and Liu, Xinchen and Cheng, Peng and Mei, Tao},
>   booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
>  pages={9664--9667},
>   year={2023}
> }
> ```
> 
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/4b56e9ed-673a-49c2-b9b2-b1f1bb88366a.png)

- **Relation Preserving Triplet Mining for Stabilising the Triplet Loss in Re-identification Systems**

> **WACV, 2023. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-Relation Preserving Triplet Mining for Stabilising the Triplet Loss.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Relation+Preserving+Triplet+Mining+for+Stabilising+the+Triplet+Loss+in+Re-identification+Systems**&btnG=)  【引用数：**3**】
>
> **论文引用**：
>
> ```
>@inproceedings{ghosh2023relation,
>   title={Relation preserving triplet mining for stabilising the triplet loss in re-identification systems},
>  author={Ghosh, Adhiraj and Shanmugalingam, Kuruparan and Lin, Wen-Yan},
>   booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
>  pages={4840--4849},
>   year={2023}
> }
> ```
> 
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 22.04.29.png" alt="截屏2023-11-12 22.04.29 " style="zoom:50%;" />

- **MSINet: Twins Contrastive Search of Multi-Scale Interaction for Object ReID**

> **CVPR, 2023. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-Gu_MSINet_Twins_Contrastive_Search_of_Multi-Scale_Interaction_for_Object_ReID_CVPR_2023_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=MSINet%3A+Twins+Contrastive+Search+of+Multi-Scale+Interaction+for+Object+ReID&btnG=) 【引用数：**6**】
>
> **论文引用**：
>
> ```
>@inproceedings{gu2023msinet,
>   title={MSINet: Twins Contrastive Search of Multi-Scale Interaction for Object ReID},
>   author={Gu, Jianyang and Wang, Kai and Luo, Hao and Chen, Chen and Jiang, Wei and Fang, Yuqiang and Zhang, Shanghang and You, Yang and Zhao, Jian},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>  pages={19243--19253},
>   year={2023}
>}
> ```
> 
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-21 10.53.47.png" alt="截屏2023-11-21 10.53.47" style="zoom:45%;" />

- **Robust and Scalable Vehicle Re-Identification via Self-Supervision**

> **CVPR, 2023. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-Khorramshahi_Robust_and_Scalable_Vehicle_Re-Identification_via_Self-Supervision_CVPRW_2023_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Robust+and+Scalable+Vehicle+Re-Identification+via+Self-Supervision&btnG=)  引用数：**3**】
>
> **论文引用**：
>
> ```
>@inproceedings{khorramshahi2023robust,
>   title={Robust and Scalable Vehicle Re-Identification via Self-Supervision},
>  author={Khorramshahi, Pirazh and Shenoy, Vineet and Chellappa, Rama},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>  pages={5294--5303},
>   year={2023}
> }
> ```
> 
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-12-11 09.13.07.png" alt="截屏2023-12-11 09.13.07 " style="zoom:70%;" />
> 
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/01184500-369f-488c-8a6f-46f5ebb768b9.png)

- **A Meta-learning Approach for Domain Generalisation across Visual Modalities in Vehicle Re-identification**

> **CVPR, 2023. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-Kamenou_A_Meta-Learning_Approach_for_Domain_Generalisation_Across_Visual_Modalities_in_CVPRW_2023_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+Meta-learning+Approach+for+Domain+Generalisation+across+Visual+Modalities+in+Vehicle+Re-identification&btnG=) 【引用数：**1**】
>
> 
>**论文引用**：
> 
>```
> @inproceedings{kamenou2023meta,
>  title={A Meta-Learning Approach for Domain Generalisation Across Visual Modalities in Vehicle Re-Identification},
>   author={Kamenou, Eleni and del Rinc{\'o}n, Jes{\'u}s Mart{\'\i}nez and Miller, Paul and Devlin-Hill, Patricia},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>   pages={385--393},
>   year={2023}
> }
> ```
>   
><img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-12-11 09.19.03.png" alt="截屏2023-12-11 09.19.03" style="zoom:50%;" />

- **CLIP-ReID: Exploiting Vision-Language Model for Image Re-Identification without Concrete Text Labels**

> **AAAI, 2023 [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-CLIP_ReID Exploiting Vision_Language Model for Image Re_Identification.pdf).  [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=CLIP-ReID%3A+Exploiting+Vision-Language+Model+for+Image+Re-Identification+without+Concrete+Text+Labels&btnG=) 【引用数：**4】
>
> **论文引用**：
>
> ```
> @inproceedings{li2023clip,
>   title={Clip-reid: Exploiting vision-language model for image re-identification without concrete text labels},
>   author={Li, Siyuan and Sun, Li and Li, Qingli},
>   booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
>   volume={37},
>   number={1},
>   pages={1405--1413},
>   year={2023}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.19.07.png" alt="截屏2023-11-12 21.19.07 " style="zoom:33%;" />

- **VehicleGAN: Pair-flexible Pose Guided Image Synthesis for Vehicle Re-identification**

> **CVPR, 2023 [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2023-VehicleGAN.pdf).  [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=VehicleGAN%3A+Pair-flexible+Pose+Guided+Image+Synthesis+for+Vehicle+Re-identification&btnG=#d=gs_cit&t=1703302231985&u=%2Fscholar%3Fq%3Dinfo%3AiU2UsHRzAdYJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN) 【引用数：**0】
>
> **论文引用**：
>
> ```
>@article{li2023vehiclegan,
>   title={VehicleGAN: Pair-flexible Pose Guided Image Synthesis for Vehicle Re-identification},
>  author={Li, Baolu and Liu, Ping and Fu, Lan and Li, Jinlong and Fang, Jianwu and Xu, Zhigang and Yu, Hongkai},
>   journal={arXiv preprint arXiv:2311.16278},
>  year={2023}
> }
> ```
> 
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/d9f0ad19-b2fe-4198-a42c-896397e9f430.png)



## 2022

- **GAN-Siamese Network for Cross-Domain Vehicle Re-Identification in Intelligent Transport Systems**

> **IEEE Transactions on Network Science and Engineering, 2022. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2022-GAN-Siamese_Network_for_Cross-Domain_Vehicle_Re-Identification_in_Intelligent_Transport_Systems.pdf) [link](https://scholar.google.co.jp/scholar?hl=zh-CN&as_sdt=0%2C5&as_ylo=2022&as_yhi=2022&as_vis=1&q=GAN-Siamese+Network+for+Cross-Domain+Vehicle+Re-Identification+in+Intelligent+Transport+Systems&btnG=)  【引用数：**50】
>
> **论文引用**：
>
> ```
> @article{zhou2022gan,
>   title={Gan-siamese network for cross-domain vehicle re-identification in intelligent transport systems},
>   author={Zhou, Zhili and Li, Yujiang and Li, Jin and Yu, Keping and Kou, Guang and Wang, Meimin and Gupta, Brij Bhooshan},
>   journal={IEEE Transactions on Network Science and Engineering},
>   year={2022},
>   publisher={IEEE}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/f7e23e98-7437-42c7-8bef-401c52eb32cd.png)

- **Recall@k Surrogate Loss with Large Batches and Similarity Mixup**

> **CVPR, 2022. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2022-Recall@k Surrogate Loss with Large Batches and Similarity Mixup.pdf) [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Recall%40k+Surrogate+Loss+with+Large+Batches+and+Similarity+Mixup&btnG=)  【引用数：**35】
>
> **论文引用**：
>
> ```
> @inproceedings{patel2022recall,
>   title={Recall@ k surrogate loss with large batches and similarity mixup},
>   author={Patel, Yash and Tolias, Giorgos and Matas, Ji{\v{r}}{\'\i}},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>   pages={7502--7511},
>   year={2022}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 22.00.44.png" alt="截屏2023-11-12 22.00.44 " style="zoom:33%;" />

- **Rethinking the Optimization of Average Precision: Only Penalizing Negative Instances before Positive Ones Is Enough**

> **AAAI, 2022. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2022-Rethinking the Optimization of Average Precision- Only Penalizing Negative Instances before Positive Ones is Enough.pdf) [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Rethinking+the+Optimization+of+Average+Precision%3A+Only+Penalizing+Negative+Instances+before+Positive+Ones+Is+Enough&btnG=) 【引用数：**8】
>
> **Problem:** Consider both negative and positive instances ranking before each positive
>
> **Contribution:**
>
> **论文引用**：Li Z, Min W, Song J, et al. Rethinking the optimization of average precision: only penalizing negative instances before positive ones is enough[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2022, 36(2): 1518-1526.
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-15 13.49.43.png" alt="截屏2023-11-15 13.49.43 " style="zoom:33%;" />
> $$
> S_\Omega = \{s_i =cos(V_q,V_i), i=0,...,m\} \tag{1}
> $$
>
> $$
> R(i, S_N) = \sum_{j\in S_N, j\not= i}^{}{\Iota\{S_j-S_i > 0\}} \tag{2}
> $$
>
> $$
> G(X; \tau) = \frac{1}{1+e^{-\frac{x}{\tau}}} \tag{3}
> $$
>
> $$
> L_{AP} = 1-\frac{1}{|S_P|}\sum_{i\in S_P}^{}{\frac{1+R(i, S_P)}{(1+R(i,S_P) + R(i,S_N))}} \tag{4}
> $$
>
> $$
> L_O = \frac{1}{|S_P|}\sum_{i\in S_P}{R(i, S_N)} \tag{5}
> $$

## 2021

- **AttributeNet: Attribute Enhanced Vehicle Re-Identification**

> **Neurocomputing, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-Attribute_ReID.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=AttributeNet%3A+Attribute+Enhanced+Vehicle+Re-Identification&btnG=)  【引用数：**18**】
>
> **论文引用**：
>
> ```
>@article{quispe2021attributenet,
>   title={Attributenet: Attribute enhanced vehicle re-identification},
>   author={Quispe, Rodolfo and Lan, Cuiling and Zeng, Wenjun and Pedrini, Helio},
>  journal={Neurocomputing},
>   volume={465},
>  pages={84--92},
>   year={2021},
>   publisher={Elsevier}
> }
> ```
> 
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.32.05.png" alt="截屏2023-11-12 21.32.05 " style="zoom:100%;" />

- **Heterogeneous Relational Complement for Vehicle Re-identification**

> **ICCV, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-Zhao_Heterogeneous_Relational_Complement_for_Vehicle_Re-Identification_ICCV_2021_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Heterogeneous+relational+complement+for+vehicle+&btnG=)  【引用数：**44**】
>
> **论文引用**：
>
> ```
> @inproceedings{zhao2021heterogeneous,
>   title={Heterogeneous relational complement for vehicle re-identification},
>   author={Zhao, Jiajian and Zhao, Yifan and Li, Jia and Yan, Ke and Tian, Yonghong},
>   booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
>   pages={205--214},
>   year={2021}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/fabfc6d4-3ec7-4097-989d-be4dc5b86cb0.png)

- **Attributes Guided Feature Learning for Vehicle Re-Identification**

> **IEEE Transactions on Emerging Topics in Computational Intelligence, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-AGNet.pdf) **[link](https://ieeexplore.ieee.org/abstract/document/9631874) 【引用数：**18**】
>
> **Problem: ** Large intra-class variation caused by view variations and illumination changes, and inter-class similarity for different identities with a similar appearance.
>
> **Contribution: ** 
>
> - A novel deep network architecture, which guided by meaningful attributes including camera views, vehicle types and colors for vehicle ReID
>
> **论文引用**：
>
> ```
> @article{li2021attributes,
>   title={Attributes guided feature learning for vehicle re-identification},
>   author={Li, Hongchao and Lin, Xianmin and Zheng, Aihua and Li, Chenglong and Luo, Bin and He, Ran and Hussain, Amir},
>   journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
>   volume={6},
>   number={5},
>   pages={1211--1221},
>   year={2021},
>   publisher={IEEE}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-30 12.36.06.png" alt="截屏2023-11-30 12.36.06" style="zoom: 100%;" />

- **PhD Learning: Learning with Pompeiu-hausdorff Distances for Video-based Vehicle Re-Identification** 

> **CVPR, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-Learning with Pompeiu-hausdorff Distances for Video-based.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=PhD+Learning%3A+Learning+with+Pompeiu-hausdorff+Distances+for+Video-based+Vehicle+Re-Identification&btnG=)  【引用数：**23**】
>
> **Problem: ** How to make full use of raw data, how to learn a robust re-ID model with noisy data.
>
> **Contribution: ** 
>
> - Create a video vehicle re-ID evaluation benchmark called VVeRI-901 and verify the performance of video-based re-ID is far better than static image-based one.
> - Propose a new Pompeiu-hausdorff distance (PhD) learning method for video-to-video matching.
>
> **论文引用**：
>
> ```
> @inproceedings{zhao2021phd,
>   title={Phd learning: Learning with pompeiu-hausdorff distances for video-based vehicle re-identification},
>   author={Zhao, Jianan and Qi, Fengliang and Ren, Guangyu and Xu, Lin},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>   pages={2225--2235},
>   year={2021}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.47.00.png" alt="截屏2023-11-12 21.47.00 " style="zoom:100%;" />



- **TransReID: Transformer-based Object Re-Identification**

> **CVPR, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-TransReID.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=TransReID%3A+Transformer-based+Object+Re-Identification&btnG=)【引用数 **549**】
>
> **论文引用**：
>
> ```
> @inproceedings{he2021transreid,
>   title={Transreid: Transformer-based object re-identification},
>   author={He, Shuting and Luo, Hao and Wang, Pichao and Wang, Fan and Li, Hao and Jiang, Wei},
>   booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
>   pages={15013--15022},
>   year={2021}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 22.14.48.png" alt="截屏2023-11-12 22.14.48 " style="zoom: 67%;" />

- **Embedding Adversarial Learning for Vehicle Re-Identification**

> **IEEE Transactions on Image Processing, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-Embedding_Adversarial_Learning_for_Vehicle_Re-Identification.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Embedding+Adversarial+Learning+for+Vehicle+re+identification&btnG=) 【引用数 **162**】
>
> **论文引用**：
>
> ```
> @article{lou2019embedding,
>   title={Embedding adversarial learning for vehicle re-identification},
>   author={Lou, Yihang and Bai, Yan and Liu, Jun and Wang, Shiqi and Duan, Ling-Yu},
>   journal={IEEE Transactions on Image Processing},
>   volume={28},
>   number={8},
>   pages={3794--3807},
>   year={2019},
>   publisher={IEEE}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-16 13.59.17.png" alt="截屏2023-11-16 13.59.17" style="zoom:33%;" />

- **A Strong Baseline for Vehicle Re-Identification**

> **CVPR, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-Baseline.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+Strong+Baseline+for+Vehicle+Re-Identification&btnG=#d=gs_cit&t=1702529752936&u=%2Fscholar%3Fq%3Dinfo%3AAht3mv2TxEMJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN)  【引用数 **41**】
>
> **Problem: ** Algorithms must be robust in different views, resolution, occlusion and illumination conditions.
>
> **Contribution:**
>
> - Analyze the main factors hindering the Vehicle Re-ID performance.
>
> **论文引用**：
>
> ```
> @inproceedings{huynh2021strong,
>   title={A strong baseline for vehicle re-identification},
>   author={Huynh, Su V},
>   booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
>   pages={4147--4154},
>   year={2021}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/5ba87d15-dd03-413d-b1d0-bdca8725c376.png)

## 2020

- **Part-Guided Attention Learning for Vehicle Instance Retrieval**

  > **ITC, 2020. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2020-Part-Guided Attention Learning.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Part-Guided+Attention+Learning+for+Vehicle+Instance+Retrieval&btnG=)  【引用数：**38**】
  >
  > **Problem：**Besides the holistic appearance of vehicles which is easily affected by the viewpoint variation and distortion, vehicle parts also provide crucial cues to differentiate near-identical vehicles.
  >
  > **Contribution:** 
  >
  > - Introduce a Part-Guided Attention Network to pinpoint the prominent part regions and effectively combine global and local information for discriminative feature learning.
  >
  > **论文引用**：
  >
  > ```
  > @article{zhang2020part,
  >   title={Part-guided attention learning for vehicle instance retrieval},
  >   author={Zhang, Xinyu and Zhang, Rufeng and Cao, Jiewei and Gong, Dong and You, Mingyu and Shen, Chunhua},
  >   journal={IEEE Transactions on Intelligent Transportation Systems},
  >   volume={23},
  >   number={4},
  >   pages={3048--3060},
  >   year={2020},
  >   publisher={IEEE}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.58.20.png" alt="截屏2023-11-12 21.58.20 " style="zoom:33%;" />

  - **Looking GLAMORous: Vehicle Re-Id in Heterogeneous Cameras Networks with Global and Local Attention**

  > **preprint, 2020. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/Part-Guided Attention Learning.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Looking+GLAMORous%3A+Vehicle+Re-Id+in+Heterogeneous+Cameras+Networks+with+Global+and+Local+Attention&btnG=)  【引用数：**29**】
  >
  > **Problem：** Existing approaches for vehicle re-id utilize global features and local features for re-id by combining multiple subnetworks and losses.
  >
  > **Contribution:** 
  >
  > - Group and layer normalization to address conflicting loss targets for re-id
  >
  > - A novel global attention module for global feature extraction, and
  >
  >   a novel local attention module for self-guided part-based local feature extraction.
  >
  > **论文引用**：
  >
  > ```
  > @article{suprem2020looking,
  >   title={Looking glamorous: Vehicle re-id in heterogeneous cameras networks with global and local attention},
  >   author={Suprem, Abhijit and Pu, Calton},
  >   journal={arXiv preprint arXiv:2002.02256},
  >   year={2020}
  > }
  > ```
  >
  > ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/b3a09e6c-c31f-4dad-a096-ed8554ae33a3.png)

  

- **Parsing-Based View-Aware Embedding Network for Vehicle Re-Identification**(PVEN)

> **CVPR, 2020. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2020-Parsing-based View-aware Embedding Network for Vehicle Re-Identification.pdf)  **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Parsing-Based+View-Aware+Embedding+Network+for+Vehicle+Re-Identification&btnG=)  【引用数 **182**】
>
> **Problem:**  the large intra-instance distance caused by different views and the subtle inter-instance discrepancy caused by similar vehicles.
>
> **Contribution:** 
>
> - Introduce a parsing network to parse a vehicle into four different views, and then align the features by mask average pooling,
> - Design a common-visible attention to focus on the common visible views, which not only shortens the distance among intra-instances, but also enlarges the discrepancy of inter-instance.
>
> **论文引用**：
>
> ```
> @inproceedings{meng2020parsing,
>   title={Parsing-based view-aware embedding network for vehicle re-identification},
>   author={Meng, Dechao and Li, Liang and Liu, Xuejing and Li, Yadong and Yang, Shijie and Zha, Zheng-Jun and Gao, Xingyu and Wang, Shuhui and Huang, Qingming},
>   booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
>   pages={7103--7112},
>   year={2020}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-15 10.14.27.png" alt="截屏2023-11-15 10.14.27 " style="zoom: 25%;" />
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-12-22 18.44.01.png" alt="截屏2023-12-22 18.44.01" style="zoom:30%;" />

- **VehicleNet: Learning Robust Visual Representa for Vehicle Re-identification**

> **Multimedia, 2020. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2020-VehicleNet.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=VehicleNet%3A+Learning+Robust+Visual+Representa+for+Vehicle+Re-identification&btnG=) 【引用数 **117**】
>
> **Problem:** Existing vehicle datasets are limited in terms of training images and viewpints.
>
> **Contribution:** 
>
> - Harnessing four public vehicle datasets, and design a simple yet effective two-stage progressive approach to learning more robust visual representation from VehicleNet.
>
> **论文引用**：
>
> ```
> @article{zheng2020vehiclenet,
>   title={VehicleNet: Learning robust visual representation for vehicle re-identification},
>   author={Zheng, Zhedong and Ruan, Tao and Wei, Yunchao and Yang, Yi and Mei, Tao},
>   journal={IEEE Transactions on Multimedia},
>   volume={23},
>   pages={2683--2693},
>   year={2020},
>   publisher={IEEE}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-15 09.54.16.png" alt="截屏2023-11-15 09.54.16 " style="zoom:33%;" />

- **VOC-ReID: Vehicle Re-identification based on Vehicle-Orientation-Camera**

> **CVPR, 2020. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2020-VOC-ReID_Vehicle_Re-Identification_Based_on_Vehicle-Orientation-Camera_CVPRW_2020_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=VOC-ReID%3A+Vehicle+Re-identification+based+on+Vehicle-Orientation-Camera&btnG=)  【引用数 **64**】
>
> **Problem: **Similarity contributed by fine-grained information would be dominated by backgroud and shape similarity.
>
> **Contribution:** 
>
> - Propose the triplet vehicle-orientation-camera re-identification
> - $D(x_i, x_j) = D_V(x_i, x_j) - \lambda_1D_o(x_i, y_i)-\lambda_2D_c(x_i, x_j)$
>
> **论文引用**：
>
> ```
> @inproceedings{zhu2020voc,
>   title={VOC-ReID: Vehicle re-identification based on vehicle-orientation-camera},
>   author={Zhu, Xiangyu and Luo, Zhenbo and Fu, Pei and Ji, Xiang},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
>   pages={602--603},
>   year={2020}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/15305208-6602-4f27-9d31-485890b53676.png)
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-16 13.34.15.png" alt="截屏2023-11-16 13.34.15" style="zoom: 33%;" />

- **Attribute-Guided Feature Learning Network for Vehicle Reidentification**

> **Multimedia, 2020. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2020-Attribute-Guided_Feature_Learning_Network_for_Vehicle_Reidentification.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Attribute-guided+feature+learning+network+for+vehicle+reidentification&btnG=) 【引用数 **84**】
>
> **Problem:** Complicated environments and diversified illuminations.
>
> **Contribution:** 
>
> - An attribute-guided module is proposed in AGNet to generate the attribute mask(AttrMask), which inversely guides to select discriminative features for category classification.
> - An Attribute-based label smoothinf(ASL) loss is presented to better train
>
> **论文引用**：
>
> ```
> @article{wang2020attribute,
>   title={Attribute-guided feature learning network for vehicle reidentification},
>   author={Wang, Huibing and Peng, Jinjia and Chen, Dongyan and Jiang, Guangqi and Zhao, Tongtong and Fu, Xianping},
>   journal={IEEE MultiMedia},
>   volume={27},
>   number={4},
>   pages={112--121},
>   year={2020},
>   publisher={IEEE}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-15 09.54.16.png" alt="截屏2023-11-15 09.54.16 " style="zoom:33%;" />

## 2019

**Vehicle Re-identification with Viewpoint-aware Metric Learning**. 

> **IEEE Transactions on Intelligent Transportation Systems, 2019.** [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Structural Analysis of Attributes for Vehicle Re-Identification and Retrieval.pdf).   [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Structural+analysis+of+attributes+for+vehicle+re-identification+and+retrieval%2C&btnG=) 【引用数：**63**】
>
> **Problem: **  the key information for identification has not been well explored in the literature.
>
> **Contribution: ** 
>
> -  Collect a vehicle dataset ‘VAC21’ which contains 7129 images of five types of vehicles. Then, we carefully label the 21 classes of structural attributes hierarchically with bounding boxes.
>
> **论文引用**：
>
> ```
> @article{zhao2019structural,
>   title={Structural analysis of attributes for vehicle re-identification and retrieval},
>   author={Zhao, Yanzhu and Shen, Chunhua and Wang, Huibing and Chen, Shengyong},
>   journal={IEEE Transactions on Intelligent Transportation Systems},
>   volume={21},
>   number={2},
>   pages={723--734},
>   year={2019},
>   publisher={IEEE}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/f6192b28-c9bc-4519-bb89-db7079c86da6.png)

- **Vehicle Re-identification with Viewpoint-aware Metric Learning**. 

  > **Elsevier, 2019.** [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Learning multi-region features for vehicle re-identification with context-based ranking method.pdf).   [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Learning+multi-region+features+for+vehicle+re-identification+with+context-based+ranking+method&btnG=) 【引用数：**42**】
  >
  > **Problem: ** Most existing vehicle re-identification methods focus on learning global features, while neglecting the importance of local features
  >
  > **Contribution: ** 
  >
  > - Hierarchical feature fusion network
  >
  > **论文引用**：
  >
  > ```
  > @article{peng2019learning,
  >   title={Learning multi-region features for vehicle re-identification with context-based ranking method},
  >   author={Peng, Jinjia and Wang, Huibing and Zhao, Tongtong and Fu, Xianping},
  >   journal={Neurocomputing},
  >   volume={359},
  >   pages={427--437},
  >   year={2019},
  >   publisher={Elsevier}
  > }
  > ```
  >
  > ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/cd853c7d-0095-4793-afcb-2c024031cf57.png)
  >
  > ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/743fd282-0030-4b34-9708-489efdc1e69e.png)

- **Vehicle Re-identification with Viewpoint-aware Metric Learning**. 

  > **CVPR, 2019.** [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Vehicle Re-identification with Viewpoint-aware Metric Learning.pdf).   [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Vehicle+Re-identification+with+Viewpoint-aware+Metric+Learning**.&btnG=) 【引用数：**192**】
  >
  > **Problem: ** The extreme viewpoint variation poses great challenges for existing approaches.
  >
  > **Contribution: ** 
  >
  > - Learns two features spaces, respectively.
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{chu2019vehicle,
  >   title={Vehicle re-identification with viewpoint-aware metric learning},
  >   author={Chu, Ruihang and Sun, Yifan and Li, Yadong and Liu, Zheng and Zhang, Chi and Wei, Yichen},
  >   booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  >   pages={8282--8291},
  >   year={2019}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.15.34.png" alt="截屏2023-11-12 21.15.34 " style="zoom:33%;" />



- **Vehicle re-identification in still images: Application of semi-supervised learning and re-ranking**

  > **Signal Processing:, 2019.** [(PDF)](/Users/huangkaiwen/Desktop/Paper/2019-Joint Semi-supervised Learning and Re-ranking.pdf)  [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Vehicle+re-identification+in+still+images%3A+Application+of+semi-supervised+learning+and+re-ranking&btnG=)  【引用数：**20**】
  >
  > **论文引用**：
  >
  > ```
  > @article{wu2019vehicle,
  >   title={Vehicle re-identification in still images: Application of semi-supervised learning and re-ranking},
  >   author={Wu, Fangyu and Yan, Shiyang and Smith, Jeremy S and Zhang, Bailing},
  >   journal={Signal Processing: Image Communication},
  >   volume={76},
  >   pages={261--271},
  >   year={2019},
  >   publisher={Elsevier}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.28.39.png" alt="截屏2023-11-12 21.28.39 " style="zoom:33%;" />

- **Partition and Reunion: A Two-Branch Neural Network for Vehicle Re-identification**

  > **CVPR, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-A Two-Branch Neural Network.pdf) **[link]([Partition and Reunion: A Two-Branch Neural Network... - Google 学术搜索](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&as_vis=1&q=Partition+and+Reunion%3A+A+Two-Branch+Neural+Network+for+Vehicle+Re-identification&btnG=)) 【引用数：**77**】
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{chen2019partition,
  >   title={Partition and reunion: A two-branch neural network for vehicle re-identification.},
  >   author={Chen, Hao and Lagadec, Benoit and Bremond, Francois},
  >   booktitle={CVPR Workshops},
  >   pages={184--192},
  >   year={2019}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.23.33.png" alt="截屏2023-11-12 21.23.33 " style="zoom:33%;" />

  - **Deep Feature Fusion with Multiple Granularity for Vehicle Re-identification** 
  
  > **CVPR, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Deep Feature Fusion with Multiple Granularity.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Deep+Feature+Fusion+with+Multiple+Granularity+for+Vehicle+Re-identification**+&btnG=) 【引用数：**22**】
  >
  > **Problem:** View-point
  >
  > **Contribution: ** 
  >
  > - DFFMG is proposed for integrating discriminative information with various granularity.
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{huang2019deep,
  >   title={Deep Feature Fusion with Multiple Granularity for Vehicle Re-identification.},
  >   author={Huang, Peixiang and Huang, Runhui and Huang, Jianjie and Yangchen, Rushi and He, Zongyao and Li, Xiying and Chen, Junzhou},
  >   booktitle={CVPR Workshops},
  >   pages={80--88},
  >   year={2019}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.37.58.png" alt="截屏2023-11-12 21.37.58 " style="zoom:33%;" />

  - **MULTI-VIEW LEARNING FOR VEHICLE RE-IDENTIFICATION** 
  
  > **ICME, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/Multi-view Learning for vehicle re-identification.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**MULTI-VIEW+LEARNING+FOR+VEHICLE+RE-IDENTIFICATION**+&btnG=)   [bib](https://scholar.googleusercontent.com/scholar.bib?q=info:jQyl3FBtuqkJ:scholar.google.com/&output=citation&scisdr=ClGxKZ37EImKxNKMSPw:AFWwaeYAAAAAZXqKUPwTWjKaiKVsS2cg8bQPEgI&scisig=AFWwaeYAAAAAZXqKULzUMbyJyEJaine8Dw3tgnk&scisf=4&ct=citation&cd=-1&hl=zh-CN)【引用数：**37**】
  >
  > **论文引用**：Lin W, Li Y, Yang X, et al. Multi-view learning for vehicle re-identification[C]//2019 IEEE international conference on multimedia and expo (ICME). IEEE, 2019: 832-837.
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 21.53.57.png" alt="截屏2023-11-12 21.53.57 " style="zoom:100%;" />
  
  **Variational representation learning for vehicle re-identification** 
  
  > **IEEE International Conference on Image Processing, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-VARIATIONAL REPRESENTATION LEARNING FOR VEHICLE RE-IDENTIFICATION.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**VARIATIONAL+REPRESENTATION+LEARNING+FOR+VEHICLE+RE-IDENTIFICATION**+&btnG=)【引用数：**31**】
  >
  > **Problem:** Existing methods tend to derive features of dimension ranging from thousands to tens of thousands.
  >
  > **Contribution:** 
  >
  > - The dimension of the learned  features can be as low as 256, variational feature learning is employed to generate variational features which are more discriminating.
  >
  > - long short term memory (LSTM) is used to learn the relationship among different viewpoints of a vehicle. The LSTM also plays as an
  >
  >   encoder to downsize the features.
  >
  > - $D_{kl}(N((\mu,\sigma),N(0,1))= -\frac{1}{2}\sum_{i=1}^{n}{(1+log(\sigma_i)-\mu^2_i-\sigma_i)}$
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{alfasly2019variational,
  >   title={Variational representation learning for vehicle re-identification},
  >   author={Alfasly, Saghir Ahmed Saghir and Hu, Yongjian and Liang, Tiancai and Jin, Xiaofeng and Zhao, Qingli and Liu, Beibei},
  >   booktitle={2019 IEEE International Conference on Image Processing (ICIP)},
  >   pages={3118--3122},
  >   year={2019},
  >   organization={IEEE}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-15 14.52.29.png" alt="截屏2023-11-15 14.52.29 "  />
  
  - **Attention Driven Vehicle Re-identification and Unsupervised Anomaly Detection for Traffic Understanding** 
  
  > **CVPR, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Khorramshahi_Attention_Driven_Vehicle_Re-identification_and_Unsupervised_Anomaly_Detection_for_Traffic_CVPRW_2019_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Attention+Driven+Vehicle+Re-identification+and+Unsupervised+Anomaly+Detection+for+Traffic+Understanding**+&btnG=)  【引用数：**43**】
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{khorramshahi2019attention,
  >   title={Attention Driven Vehicle Re-identification and Unsupervised Anomaly Detection for Traffic Understanding.},
  >   author={Khorramshahi, Pirazh and Peri, Neehar and Kumar, Amit and Shah, Anshul and Chellappa, Rama},
  >   booktitle={CVPR Workshops},
  >   pages={239--246},
  >   year={2019}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-15 16.14.49.png" alt="截屏2023-11-15 16.14.49" style="zoom:67%;" />
  
  - **Vehicle Re-Identification Using Quadruple Directional Deep Learning Features**
  
  > **IEEE Transactions on Intelligent Transportation Systems**, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-QD-DLP.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Vehicle+Re-Identification+Using+Quadruple+Directional+Deep+Learning+Features&btnG=#d=gs_cit&t=1703238457522&u=%2Fscholar%3Fq%3Dinfo%3A0rrutdKwR_4J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN) 【引用数：**152】
  >
  > **Problem:**  Resist the adverse effect of viewpoint variations
  >
  > **Contribution:**
  >
  > -  Use quadruple directional deep learning networks to extract quadruple directional deep learning features.
  >
  > **论文引用**：
  >
  > ```
  > @article{zhu2019vehicle,
  >   title={Vehicle re-identification using quadruple directional deep learning features},
  >   author={Zhu, Jianqing and Zeng, Huanqiang and Huang, Jingchang and Liao, Shengcai and Lei, Zhen and Cai, Canhui and Zheng, Lixin},
  >   journal={IEEE Transactions on Intelligent Transportation Systems},
  >   volume={21},
  >   number={1},
  >   pages={410--420},
  >   year={2019},
  >   publisher={IEEE}
  > }
  > ```
  >
  > ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/c997159b-0288-4129-a329-bae0c8550be9.png)
  
  
  
  - **A Dual-Path Model With Adaptive Attention For Vehicle Re-Identification** 
  
  > **CVPR, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-AAVER.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+Dual-Path+Model+With+Adaptive+Attention+For+Vehicle+Re-Identification&btnG=#d=gs_cit&t=1702529103907&u=%2Fscholar%3Fq%3Dinfo%3AQiglIJ_1v80J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN) 【引用数：**225**】
  >
  > **Problem: ** Most of methods are designed to focus attention on key-point locations, depending on the orientation, the contribution of each key-point varies.
  >
  > **Contribution: ** 
  >
  > - The global appearance path captures macroscopic vehicle features while the orientation conditioned part appearance path learns to catures localized discriminative features by focusing attention on the most infomative key-points.
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{khorramshahi2019dual,
  >   title={A dual-path model with adaptive attention for vehicle re-identification},
  >   author={Khorramshahi, Pirazh and Kumar, Amit and Peri, Neehar and Rambhatla, Sai Saketh and Chen, Jun-Cheng and Chellappa, Rama},
  >   booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  >   pages={6132--6141},
  >   year={2019}
  > }
  > ```
  >
  > <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-30 12.00.22.png" alt="截屏2023-11-30 12.00.22" style="zoom:100%;" />
  
  - **Part-regularized Near-duplicate Vehicle Re-identification** 
  
  > **CVPR, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-He_Part-Regularized_Near-Duplicate_Vehicle_Re-Identification_CVPR_2019_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Part-regularized+Near-duplicate+Vehicle+Re-identification&btnG=) 【引用数：**296**】
  >
  > **Problem:** Distinguish different instances with nearly identical appearances  
  >
  > **Contribution:** 
  >
  > -  Propose a simple but effcient part-regularized discriminative feature preserving method
  > - Introduce an detection branch to integrate part constrains.
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{he2019part,
  >   title={Part-regularized near-duplicate vehicle re-identification},
  >   author={He, Bing and Li, Jia and Zhao, Yifan and Tian, Yonghong},
  >   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  >   pages={3997--4005},
  >   year={2019}
  > }
  > ```
  >
  > ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/5d04fba3-8e2a-4898-a2cc-53b53e887595.png)
  
  - **Embedding Adversarial Learning for Vehicle Re-Identification** 
  
  > **IEEE Transactions on Image Processing**, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Embedding_Adversarial_Learning_for_Vehicle_Re-Identification.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Embedding+Adversarial+Learning+for+Vehicle+Re-Identification&btnG=) 【引用数：**165】
  >
  > **Problem:** The high similarties of different real-worl vehicles and great diversities of the acquisition views pose grand challenges 
  >
  > **Contribution:** 
  >
  > -  Propose a novel end-to-end embedding adversarial learning network(EALN) that is capable of generating samples localizaed in the embeding space.
  >
  > **论文引用**：
  >
  > ```
  > @article{lou2019embedding,
  >   title={Embedding adversarial learning for vehicle re-identification},
  >   author={Lou, Yihang and Bai, Yan and Liu, Jun and Wang, Shiqi and Duan, Ling-Yu},
  >   journal={IEEE Transactions on Image Processing},
  >   volume={28},
  >   number={8},
  >   pages={3794--3807},
  >   year={2019},
  >   publisher={IEEE}
  > }
  > ```
  >
  > ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/98fab494-45ab-4ed7-9185-e9461da4cc3e.png)
  
  - **Bag of Tricks and A Strong Baseline for Deep Person Re-identification** 
  
  > **CVPR**, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Luo_Bag_of_Tricks_and_a_Strong_Baseline_for_Deep_Person_CVPRW_2019_paper.pdf) **[link](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&as_vis=1&q=Bag+of+Tricks+and+A+Strong+Baseline+for+Deep+Person+Re-identification&btnG=) 【引用数：**1156】
  >
  > **Contribution:** 
  >
  > -  Baseline
  >
  > **论文引用**：
  >
  > ```
  > @inproceedings{luo2019bag,
  >   title={Bag of tricks and a strong baseline for deep person re-identification},
  >   author={Luo, Hao and Gu, Youzhi and Liao, Xingyu and Lai, Shenqi and Jiang, Wei},
  >   booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  >   pages={0--0},
  >   year={2019}
  > }
  > ```
  >
  > ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/dacfbd72-3097-4bb2-a23c-61604850aa56.png)
  
  

## 2018

- **Viewpoint-aware Attentive Multi-view Inference for Vehicle Re-identification**

> **CVPR, 2018. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2018-Viewpoint-aware Attentive Multi-view ) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Viewpoint-aware+Attentive+Multi-view+Inference+for+Vehicle+Re-identification&btnG=)【引用数 **339**】
>
> **Problem:** Different vehicle identities with a similar appearance have little inter-instance discrepancy while one vehicle usually has large intra-instance differences under viewpoint and illutmination variations.
>
> **Contribution:** 
>
> - Only requires visual information to solve the multi-view vehicle re-ID problem.
>
> **论文引用**：
>
> ```
> @inproceedings{zhou2018aware,
>   title={Aware attentive multi-view inference for vehicle re-identification},
>   author={Zhou, Yi and Shao, Ling},
>   booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
>   pages={6489--6498},
>   year={2018}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-12 22.25.48.png" alt="截屏2023-11-12 22.25.48 " style="zoom:100%;" />

- **RAM: A REGION-AWARE DEEP MODEL FOR VEHICLE RE-IDENTIFICATION**

> **IEEE International Conference on Multimedia and Expo, 2018. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2018-RAM_A_Region-Aware_Deep_Model_for_Vehicle_Re-Identification.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=RAM%3A+A+REGION-AWARE+DEEP+MODEL+FOR+VEHICLE+RE-IDENTIFICATION&btnG=)   【引用数 **250**】
>
> **Problem:** Previous works on vehicle Re-ID mainly focus on extracting global features and learning distance metrics.
>
> **Contribution:**
>
> - Propose a Region-Aware deep model (RAM) to embed the detailed visual cues.
> - Introduce a novel learning algorithm to jointly use vehicle IDs, types/models, and colors to train the RAM.
>
> **论文引用**：
>
> ```
> @inproceedings{liu2018ram,
>   title={Ram: a region-aware deep model for vehicle re-identification},
>   author={Liu, Xiaobin and Zhang, Shiliang and Huang, Qingming and Gao, Wen},
>   booktitle={2018 IEEE International Conference on Multimedia and Expo (ICME)},
>   pages={1--6},
>   year={2018},
>   organization={IEEE}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-11-15 15.50.04.png" alt="截屏2023-11-15 15.50.04" style="zoom: 67%;" />

- **RAM: A REGION-AWARE DEEP MODEL FOR VEHICLE RE-IDENTIFICATION**

> **IEEE conference on computer vision and pattern recognition, 2018. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2018-Wu_Vehicle_Re-Identification_With_CVPR_2018_paper.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Vehicle+re-identification+with+the+space-time+prior%2C&btnG=#d=gs_cit&t=1704346130200&u=%2Fscholar%3Fq%3Dinfo%3Aw4NG_scyUd4J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN)   【引用数 **46**】
>
> **Problem:**  the difficulties in data labeling, visual domain mismatch between datasets and diverse appearance of the same vehicle.
>
> **Contribution:**
>
> -  The adaptive feature learning technique based on the space-time prior to address these issues.
>
> **论文引用**：
>
> ```
> @inproceedings{wu2018vehicle,
>   title={Vehicle re-identification with the space-time prior},
>   author={Wu, Chih-Wei and Liu, Chih-Ting and Chiang, Cheng-En and Tu, Wei-Chih and Chien, Shao-Yi},
>   booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
>   pages={121--128},
>   year={2018}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/e0c8564b-09f4-4bf4-a557-83263ba8600f.png)

## 2017

- **Orientation Invariant Feature Embedding and Spatial Temporal Regularization for Vehicle Re-identification**

> **ICCV, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2017-Orientation_Invariant_Feature_ICCV_2017_paper.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Orientation+Invariant+Feature+Embedding+and+Spatial+Temporal+Regularization+for+Vehicle+Re-identification**&btnG=) 【引用数 **397**】
>
> **Problems:**
>
> **Contribution:** 
>
> - Propose an orientation invariant feature embedding module, with orientation invariant feature embedding ,  local region features of different orientations can be extracted based on 20 key point locations and can be well aligned and combined.
> - Propose a spatial-temporal regularization module, the log-normal distribution is adopted to model the spatial-temporal contrains.
>
> **论文引用**：
>
> ```
> @inproceedings{wang2017orientation,
>   title={Orientation invariant feature embedding and spatial temporal regularization for vehicle re-identification},
>   author={Wang, Zhongdao and Tang, Luming and Liu, Xihui and Yao, Zhuliang and Yi, Shuai and Shao, Jing and Yan, Junjie and Wang, Shengjin and Li, Hongsheng and Wang, Xiaogang},
>   booktitle={Proceedings of the IEEE international conference on computer vision},
>   pages={379--387},
>   year={2017}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/df3bdebd-978e-4d71-ab6e-92932248dbf8.png)

- **PROVID: Progressive and Multimodal Vehicle Reidentification for Large-Scale Urban Surveillance**

> **IEEE Transactions on Multimedia, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2017-PROVID.pdf) ** [link](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&as_vis=1&q=PROVID%3A+Progressive+and+Multimodal+Vehicle+Reidentification+for+Large-Scale+Urban+Surveillance&btnG=) 【引用数 **395**】
>
> **Problem:**  Most existing approaches mainly consider the general vehicle appearance for reidentification while overlooking the distinct vehicle identifier, such as the license plate number.
>
> **Contribution:**
>
> - Not only utilizes the multimodality data in large-scale video surveillance, such as visual features, license plates, camera locations, and contextual information, but also considers vehicle reidentification in two progressive procedures: coarse-to-fine search in the feature domain, and near-to-distant search in the physical space.
>
> **论文引用**：
>
> ```
> @article{liu2017provid,
>   title={Provid: Progressive and multimodal vehicle reidentification for large-scale urban surveillance},
>   author={Liu, Xinchen and Liu, Wu and Mei, Tao and Ma, Huadong},
>   journal={IEEE Transactions on Multimedia},
>   volume={20},
>   number={3},
>   pages={645--658},
>   year={2017},
>   publisher={IEEE}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/0d22859f-d129-409e-9b54-ef0ac22ce28a.png)

- **DEEP JOINT DISCRIMINATIVE LEARNING FOR VEHICLE RE-IDENTIFICATION AND RETRIEVAL**

> **ICME, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2017-triplet-wise.pdf) ** [link ](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&as_vis=1&q=Improving+triplet-wise+training+of+convolutional+neural+network+for+vehicle+re-identification&btnG=)【引用数 **114**】
>
> **Problem: ** Triplet Loss 
>
> **Contribution:** 
>
> - A stronger constraint namely classificaition-oriented loss is augmented with the original triplet loss
> - A new triplet sampling method based on pairwise images is designed
>
> **论文引用**：
>
> ```
> @inproceedings{zhang2017improving,
>   title={Improving triplet-wise training of convolutional neural network for vehicle re-identification},
>   author={Zhang, Yiheng and Liu, Dong and Zha, Zheng-Jun},
>   booktitle={2017 IEEE International Conference on Multimedia and Expo (ICME)},
>   pages={1386--1391},
>   year={2017},
>   organization={IEEE}
> }
> ```
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-12-22 14.21.16.png" alt="截屏2023-12-22 14.21.16" style="zoom:40%;" />

- **DEEP JOINT DISCRIMINATIVE LEARNING FOR VEHICLE RE-IDENTIFICATION AND RETRIEVAL**

> **ICIP, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/li2017.pdf) ** [link](https://scholar.google.com.hk/scholar?q=deep+joint+discriminative+learning+for+vehicle&hl=zh-CN&as_sdt=0%2C5&as_vis=1&as_ylo=&as_yhi=)  【引用数 **67**】
>
> **论文引用**：Wang Z, Tang L, Liu X, et al. Orientation invariant feature embedding and spatial temporal regularization for vehicle re-identification[C]//Proceedings of the IEEE international conference on computer vision. 2017: 379-387.
>
> <img src="/Users/huangkaiwen/Library/Application Support/typora-user-images/截屏2023-12-11 10.46.27.png" alt="截屏2023-12-11 10.46.27" style="zoom:25%;" />

- **Learning Deep Neural Networks for Vehicle Re-ID with Visual-spatio-temporal Path Proposals**

> **CVPR, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2017-Shen_Learning_Deep_Neural_ICCV_2017_paper.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=+Learning+deep+neural+networks+for+vehicle+re%02id+with+visual-spatio-temporal+path+proposals&btnG=)  【引用数 **343**】
>
> **Problem: ** The visual differences between pairs of vehicle images are usually subtle
>
> **Contribution: ** 
>
> **论文引用**：
>
> ```
> @inproceedings{shen2017learning,
>   title={Learning deep neural networks for vehicle re-id with visual-spatio-temporal path proposals},
>   author={Shen, Yantao and Xiao, Tong and Li, Hongsheng and Yi, Shuai and Wang, Xiaogang},
>   booktitle={Proceedings of the IEEE international conference on computer vision},
>   pages={1900--1909},
>   year={2017}
> }
> ```

- **MULTI-MODAL METRIC LEARNING FOR VEHICLE RE-IDENTIFICATION IN TRAFFIC SURVEILLANCE ENVIRONMENT**

> **ICIP, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2017-Multi-modal_metric_learning_for_vehicle_re-identification_in_traffic_surveillance_environment.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Multi-modal+metric+learning+for+vehicle+re%02identification+in+traffic+surveillance+environment&btnG=)  【引用数 **36**】
>
> **论文引用**：
>
> ```
> @inproceedings{tang2017multi,
>   title={Multi-modal metric learning for vehicle re-identification in traffic surveillance environment},
>   author={Tang, Yi and Wu, Di and Jin, Zhi and Zou, Wenbin and Li, Xia},
>   booktitle={2017 IEEE International Conference on Image Processing (ICIP)},
>   pages={2254--2258},
>   year={2017},
>   organization={IEEE}
> }
> ```
>
> ![](https://gulinall-hkw.oss-cn-shenzhen.aliyuncs.com/4cca69df-c3ae-47f8-ad55-da8286c56f78.png)

- **Learning Deep Neural Networks for Vehicle Re-ID with Visual-spatio-temporal Path Proposals**

> **ICCV, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2017-Shen_Learning_Deep_Neural_ICCV_2017_paper.pdf) ** [link ](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=+Learning+deep+neural+networks+for+vehicle+re%02id+with+visual-spatio-temporal+path+proposals&btnG=)【引用数 **343**】
>
> **Problem: ** The visual differences between pairs of vehicle images are usually subtle, Existing vehicle re-identification methods for the spatio-temporal relations between vehicle images.
>
> **Contribution:**  
>
> - A stronger constraint namely classificaition-oriented loss is augmented with the original triplet loss
> - A new triplet sampling method based on pairwise images is designed
>
> **论文引用**：
>
> ```
> @inproceedings{shen2017learning,
>   title={Learning deep neural networks for vehicle re-id with visual-spatio-temporal path proposals},
>   author={Shen, Yantao and Xiao, Tong and Li, Hongsheng and Yi, Shuai and Wang, Xiaogang},
>   booktitle={Proceedings of the IEEE international conference on computer vision},
>   pages={1900--1909},
>   year={2017}
> }
> ```
>

# DataSet

- **Deep Relative Distance Learning: Tell the Difference Between Similar Vehicles (VehicleID)** 

> **CVPR, 2016. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2016-Deep Relative Distance Learning.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Deep+Relative+Distance+Learning%3A+Tell+the+Difference+Between+Similar+Vehicles+%28VehicleID%29**&btnG=) 【引用数：**754**】
>
> **论文引用**：
>
> ```
> @inproceedings{liu2016deep,
>   title={Deep relative distance learning: Tell the difference between similar vehicles},
>   author={Liu, Hongye and Tian, Yonghong and Yang, Yaowei and Pang, Lu and Huang, Tiejun},
>   booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
>   pages={2167--2175},
>   year={2016}
> }
> ```

- **VERI-Wild: A Large Dataset and a New Method for Vehicle Re-Identification in the Wild (Veri-wild)** 

> **CVPR, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-VERI_Wild.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=VERI-Wild%3A+A+Large+Dataset+and+a+New+Method+for+Vehicle+Re-Identification+in+the+Wild+%28Veri-wild%29&btnG=) 【引用数：**262**】
>
> **论文引用**：
>
> ```
> @inproceedings{lou2019veri,
>   title={Veri-wild: A large dataset and a new method for vehicle re-identification in the wild},
>   author={Lou, Yihang and Bai, Yan and Liu, Jun and Wang, Shiqi and Duan, Lingyu},
>   booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
>   pages={3235--3243},
>   year={2019}
> }
> ```

- **LARGE-SCALE VEHICLE RE-IDENTIFICATION IN URBAN SURVEILLANCE VIDEOS (Veri -FACT)**

> **ICME, 2016. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2016-LARGE-SCALE VEHICLE RE-IDENTIFICATION IN URBAN SURVEILLANCE VIDEOS.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=ARGE-SCALE+VEHICLE+RE-IDENTIFICATION+IN+URBAN+SURVEILLANCE+VIDEOS+%28Veri%29&btnG=)  【引用数 **502**】
>
> **论文引用**：
>
> ```
> @inproceedings{liu2016large,
>   title={Large-scale vehicle re-identification in urban surveillance videos},
>   author={Liu, Xinchen and Liu, Wu and Ma, Huadong and Fu, Huiyuan},
>   booktitle={2016 IEEE international conference on multimedia and expo (ICME)},
>   pages={1--6},
>   year={2016},
>   organization={IEEE}
> }
> ```

- **A Deep Learning-Based Approach to Progressive Vehicle Re-identification for Urban Surveillance (VERI-776)**

> **ECCV, 2016. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2016-A Deep Learning-Based Approach to Progressive Vehicle Re-identification for Urban Surveillance.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+Deep+Learning-Based+Approach+to+Progressive+Vehicle+Re-identification+for+Urban+Surveillance+%28VERI-776%29&btnG=) 【引用数 **545**】
>
> **论文引用**：
>
> ```
> @inproceedings{liu2016deep,
>   title={A deep learning-based approach to progressive vehicle re-identification for urban surveillance},
>   author={Liu, Xinchen and Liu, Wu and Mei, Tao and Ma, Huadong},
>   booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
>   pages={869--884},
>   year={2016},
>   organization={Springer}
> }
> ```

- **CityFlow: A City-Scale Benchmark for Multi-Target Multi-Camera Vehicle Tracking and Re-Identification (CityFlow)**

> **CVPR, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-CityFlow.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=CityFlow%3A+A+City-Scale+Benchmark+for+Multi-Target+Multi-Camera+Vehicle+Tracking+and+Re-Identification+%28CityFlow%29&btnG=)  【引用数 **360**】
>
> **论文引用**：
>
> ```
> @inproceedings{tang2019cityflow,
>   title={Cityflow: A city-scale benchmark for multi-target multi-camera vehicle tracking and re-identification},
>   author={Tang, Zheng and Naphade, Milind and Liu, Ming-Yu and Yang, Xiaodong and Birchfield, Stan and Wang, Shuo and Kumar, Ratnesh and Anastasiu, David and Hwang, Jenq-Neng},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>   pages={8797--8806},
>   year={2019}
> }
> ```

- **A Large-Scale Car Dataset for Fine-Grained Categorization and Verification（CompCars）**

> **CVPR, 2015. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2015-Yang_A_Large-Scale_Car_2015_CVPR_paper.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=+A+large-scale+car+dataset+for+fine-grained++categorization+and+verification&btnG=)  【引用数 **955**】
>
> **论文引用**：
>
> ```
> @inproceedings{yang2015large,
>   title={A large-scale car dataset for fine-grained categorization and verification},
>   author={Yang, Linjie and Luo, Ping and Change Loy, Chen and Tang, Xiaoou},
>   booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
>   pages={3973--3981},
>   year={2015}
> }
> ```

# Survey

- **A Survey of Vehicle Re-Identification Based on Deep Learning**

> **Access, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Survey on Deep learning.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+Survey+of+Vehicle+Re-Identification+Based+on+Deep+Learning&btnG=)  【引用数 **40**】
>
> **论文引用**：
>
> ```
> @article{wang2019survey,
>   title={A survey of vehicle re-identification based on deep learning},
>   author={Wang, Hongbo and Hou, Jiaying and Chen, Na},
>   journal={IEEE Access},
>   volume={7},
>   pages={172443--172469},
>   year={2019},
>   publisher={IEEE}
> }
> ```

- **A survey of advances in vision-based vehicle re-identification**

> **CVIU, 2019. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2019-Survey.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+survey+of+advances+in+vision-based+vehicle+re-identification&btnG=) 【引用数 **136**】
>
> **论文引用**：
>
> ```
> @article{khan2019survey,
>   title={A survey of advances in vision-based vehicle re-identification},
>   author={Khan, Sultan Daud and Ullah, Habib},
>   journal={Computer Vision and Image Understanding},
>   volume={182},
>   pages={50--63},
>   year={2019},
>   publisher={Elsevier}
> }
> ```

- **Trends in Vehicle Re-Identification Past, Present, and Future: A Comprehensive Review**

> **MDPI, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2021-Trends in Vehicle Re-identification Past, Present, and Future- A Comprehensive Review.pdf) **[link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=**Trends+in+Vehicle+Re-Identification+Past%2C+Present%2C+and+Future%3A+A+Comprehensive+Review**&btnG=) 【引用数 **29**】
>
> **论文引用**：
>
> ```
> @article{zakria2021trends,
>   title={Trends in vehicle re-identification past, present, and future: A comprehensive review},
>   author={Zakria and Deng, Jianhua and Hao, Yang and Khokhar, Muhammad Saddam and Kumar, Rajesh and Cai, Jingye and Kumar, Jay and Aftab, Muhammad Umar},
>   journal={Mathematics},
>   volume={9},
>   number={24},
>   pages={3162},
>   year={2021},
>   publisher={MDPI}
> }
> ```

# Tool

- **GroupFace: Learning Latent Groups and Constructing Group-based Representations for Face Recognition**

> **CVPR, 2020. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2020-MultiHeads.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=GroupFace%3A+Learning+Latent+Groups+and+Constructing+Group-based+Representations+for+Face+Recognition&btnG=) 【引用数 **100**】
>
> **论文引用**：
>
> ```
> @inproceedings{kim2020groupface,
>   title={Groupface: Learning latent groups and constructing group-based representations for face recognition},
>   author={Kim, Yonghyun and Park, Wonpyo and Roh, Myung-Cheol and Shin, Jongju},
>   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
>   pages={5621--5630},
>   year={2020}
> }
> ```

- **A Survey on Curriculum Learning**

> **IEEE Transactions on Pattern Analysis and Machine, 2021. [(PDF)](/Users/huangkaiwen/Desktop/Paper/2021-Survey on Curriculum Learning.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=GroupFace%3A+Learning+Latent+Groups+and+Constructing+Group-based+Representations+for+Face+Recognition&btnG=) 【引用数 **321**】
>
> **论文引用**：
>
> ```
> @article{wang2021survey,
>   title={A survey on curriculum learning},
>   author={Wang, Xin and Chen, Yudong and Zhu, Wenwu},
>   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
>   volume={44},
>   number={9},
>   pages={4555--4576},
>   year={2021},
>   publisher={IEEE}
> }
> ```

- **Curriculum Learning**

> **Proceedings of the 26th annual international conference on machine learning, 2009. [(PDF)](/Users/huangkaiwen/Desktop/Paper/vehicle-reid/2009-curriculum learning.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Curriculum+learning&btnG=) 【引用数 **5565**】 
>
> **论文引用**：
>
> ```
> @inproceedings{bengio2009curriculum,
>   title={Curriculum learning},
>   author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
>   booktitle={Proceedings of the 26th annual international conference on machine learning},
>   pages={41--48},
>   year={2009}
> }
> ```

- **GMS: Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence**

> **CVPR, 2017. [(PDF)](/Users/huangkaiwen/Desktop/Paper/2017-Bian_GMS_Grid-based_Motion_CVPR_2017_paper.pdf) ** [link](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=GMS%3A+Grid-based+Motion+Statistics+for+Fast%2C+Ultra-robust+Feature+Correspondence&btnG=) 【引用数: **680**】
>
> **论文引用**：
>
> ```
> @inproceedings{bian2017gms,
>   title={Gms: Grid-based motion statistics for fast, ultra-robust feature correspondence},
>   author={Bian, JiaWang and Lin, Wen-Yan and Matsushita, Yasuyuki and Yeung, Sai-Kit and Nguyen, Tan-Dat and Cheng, Ming-Ming},
>   booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
>   pages={4181--4190},
>   year={2017}
> }
> ```



 .
